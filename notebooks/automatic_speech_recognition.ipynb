{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6f03b-0ec3-443a-947f-d6b8b44682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import resample\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c1845-73ee-457a-9233-d775eac5fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e411903-6dd5-427b-89da-78c2b1628f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932eb0c-92c7-4e74-9deb-e5416f0eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10649025-194d-462e-bee6-5dc988de2380",
   "metadata": {},
   "source": [
    "## Load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f284595-a273-4010-a2cc-c8fa7c525296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file and get the sample rate and audio data\n",
    "sample_rate, audio_data = wavfile.read(f'../artifacts/audio/e9566c13-b385-46c1-b794-d8f419628aff.wav')\n",
    "\n",
    "# Ensure audio data is within range for int16\n",
    "audio_data = np.clip(audio_data, -32768, 32767).astype(np.int16)\n",
    "\n",
    "# audio_data is now a NumPy array containing the audio samples\n",
    "# sample_rate contains the sample rate of the audio file\n",
    "\n",
    "# You can perform operations on the audio data as needed\n",
    "# For example, you can print the length of the audio in seconds:\n",
    "audio_length_seconds = len(audio_data) / sample_rate\n",
    "print(f\"Audio Length: {audio_length_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d6f60-d4b8-407c-8cbe-ed9fe8c7a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a74864-7a71-434f-a45d-a73948d5dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_data.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5282ce-3228-4f80-8498-9491ae63cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target sample rate (16,000 Hz)\n",
    "target_sample_rate = 16000\n",
    "\n",
    "# Calculate the resampling factor\n",
    "resampling_factor = target_sample_rate / sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9f88b-32b9-4b89-b1cf-d6493fd47b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the audio data\n",
    "resampled_audio_data = resample(audio_data, int(len(audio_data) * resampling_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46d083-4074-4761-a0b0-d3a288c3c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(resampled_audio_data.T, rate=target_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5b20d-cfe6-4db9-88cc-b6cc5d2f3971",
   "metadata": {},
   "source": [
    "## Load wav2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a056c67-3480-4f69-ab64-2e6bc7772bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'facebook/wav2vec2-base-960h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e2c8c-7695-44fe-a6da-d6350f1d5515",
   "metadata": {},
   "outputs": [],
   "source": [
    " processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    " model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b17da4-eb6a-44ae-84ab-44b3d7426fac",
   "metadata": {},
   "source": [
    "#### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bfcd28-ac60-4478-b38d-7b5e7bafef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(f'./processors/{model_id}')\n",
    "model.save_pretrained(f'./models/{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e129c-9dd7-4033-b506-1a65b599b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = processor(resampled_audio_data.T, \n",
    "                         return_tensors=\"pt\", \n",
    "                         padding=\"longest\",\n",
    "                         sampling_rate=target_sample_rate\n",
    "                        ).input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00279322-6a72-4b12-9ea3-855af5077bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # retrieve logits\n",
    " logits = model(input_values).logits\n",
    " \n",
    " # take argmax and decode\n",
    " predicted_ids = torch.argmax(logits, dim=-1)\n",
    " transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5d5fe-9906-4b88-8439-0cf898dc060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176466d-f289-4cdc-9ffe-25a3cce22a91",
   "metadata": {},
   "source": [
    "## Load wav2vec large-medical-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66158ece-11fc-4f12-8fc4-5fa118652993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'srujan00123/wav2vec2-large-medical-speed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cb427-2f60-43bf-bb8f-8985810f5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    " processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    " model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af131f7f-5bfb-434c-b545-0f653e59651b",
   "metadata": {},
   "source": [
    "#### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448a135-a581-494f-8291-af22bc6f1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(f'./processors/{model_id}')\n",
    "model.save_pretrained(f'./models/{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c365842-69b8-4ed6-a09a-675620d30941",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = processor(resampled_audio_data.T, \n",
    "                         return_tensors=\"pt\", \n",
    "                         padding=\"longest\",\n",
    "                         sampling_rate=target_sample_rate\n",
    "                        ).input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a47bc-f818-493d-b2e1-341d94f4e090",
   "metadata": {},
   "outputs": [],
   "source": [
    " # retrieve logits\n",
    " logits = model(input_values).logits\n",
    " \n",
    " # take argmax and decode\n",
    " predicted_ids = torch.argmax(logits, dim=-1)\n",
    " transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46124c01-ab0f-427f-92bc-d2c04dae76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a95e6-55b0-4d26-8e6a-03ec3c99208f",
   "metadata": {},
   "source": [
    "## Load whisper large v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618a54b-d434-4fcf-91b7-d251b280b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066db4d-21c2-40f3-9e58-1c4918a1b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'openai/whisper-large-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5985f8-fba2-4db7-a45c-0b4fa7fcd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(f'../models/{model_id}')\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41316fab-54d2-41fa-a288-015f2db76b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = processor(resampled_audio_data.T, \n",
    "                         return_tensors=\"pt\",\n",
    "                         sampling_rate=target_sample_rate\n",
    "                        ).input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4be7c6-62c2-49fc-babd-1064f3a5aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = model.generate(input_values)\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64695ab2-7e7a-49e4-9871-2a4b5c093698",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
